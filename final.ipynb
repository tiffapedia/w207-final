{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W207 Summer 2018 Final Project \n",
    "---\n",
    "\n",
    "**Authors:** Divya Gorantla, Ram Iyer, Tiffany Jaya, Steve Sanders <br/>\n",
    "**Date:** 5 August 2018\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Exploratory Data Analysis](#eda)\n",
    "  1. [Load libraries](#load-libraries)\n",
    "  2. [Load data](#load-data)\n",
    "  3. [Identify the train labels](#identify-the-train-labels)\n",
    "  4. [Identify the train features](#identify-the-train-features)\n",
    "  5. [Address concerns about the datasets](#address-concerns-about-the-datasets)\n",
    "3. [Feature Engineering](#feature-engineering)\n",
    "4. [Models](#models)\n",
    "5. [Ensemble Models](#ensemble-models)\n",
    "6. [Stacking Models](#stacking-models)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='introduction'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Our goal in this project is to classify an observed 30 x 30 meter land into one of the seven forest cover types found in the Roosevelt National Forest of Northern Colarado: \n",
    "\n",
    "| Forest Cover Type  | Tree   | Leaf  | \n",
    "| ------------------ |:------:| -----:| \n",
    "| Spruce/Fir         | <img src='./img/spruce-tree.jpg' alt='Spruce tree' height='65px' width='65px'/><br /><img src='./img/fir-tree.jpg' alt='Fir tree' height='65px' width='65px'/> | <img src='./img/spruce.jpg' alt='Spruce leaf' height='65px' width='65px'/><br /><img src='./img/fir.jpg' alt='Fir leaf' height='65px' width='65px'/> | \n",
    "| Lodgepole Pine     | <img src='./img/lodgepole-pine-tree.jpg' alt='Lodgepole Pine tree' height='65px' width='65px'/> | <img src='./img/lodgepole-pine.jpg' alt='Lodgepole Pine leaf' height='65px' width='65px'/> | \n",
    "| Ponderosa Pine     | <img src='./img/ponderosa-pine-tree.jpg' alt='Ponderosa Pine tree' height='65px' width='65px'/> | <img src='./img/ponderosa-pine.jpg' alt='Ponderosa Pine leaf' height='65px' width='65px'/> |\n",
    "| Cottonwood/Willow  | <img src='./img/cottonwood-tree.jpg' alt='Cottonwood tree' height='65px' width='65px'/><br /><img src='./img/willow-tree.jpg' alt='Willow tree' height='65px' width='65px'/> | <img src='./img/cottonwood.jpg' alt='Cottonwood leaf' height='65px' width='65px'/><br /><img src='./img/willow.jpg' alt='Willow leaf' height='65px' width='65px'/> |\n",
    "| Aspen              | <img src='./img/aspen-tree.jpg' alt='Aspen tree' height='65px' width='65px'/> | <img src='./img/aspen.jpg' alt='Aspen leaf' height='65px' width='65px'/> | \n",
    "| Douglas-Fir        | <img src='./img/douglas-fir-tree.jpg' alt='Douglas-Fir tree' height='65px' width='65px'/> | <img src='./img/douglas-fir.jpg' alt='Douglas-Fir leaf' height='65px' width='65px'/> | \n",
    "| Krummholz <br />(stunted trees) | <img src='./img/krummholz-tree.jpg' alt='Krummholz tree' height='65px' width='65px'/> | |\n",
    "\n",
    "Fortunately for us, 15,120 of these observations have been labeled to their respective forest cover types. We can then use this labeled dataset to train several different models and compare which model can best accurately classify the forest cover type based on just the cartographic information. \n",
    "\n",
    "What we have found is that random forest classifier perform best among the three models we have tested with an accuracy score of 77.2%.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "All cartographic information that we use as features to determine the forest cover type has been collected by the US Geological Survey (USGS) and US Forest Service (USFS). The associating labels were derived separately by the USFS Region 2 Resource Information System. We download them from the Kaggle website via the Kaggle API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load-libraries'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# general libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plot libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# preprocessing (aka feature engineering)\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# model definition\n",
    "from sklearn import svm as SVM\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# model metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load-data'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "We used the Kaggle API to download the data directly from the Kaggle website. \n",
    "\n",
    "To use the Kaggle API, please follow these instructions:\n",
    "\n",
    "1. Login to your Kaggle account\n",
    "2. Select 'My account'\n",
    "3. Select 'Create New API Token'\n",
    "4. Place the token 'kaggle.json' into ~/.kaggle\n",
    "\n",
    "We decided to comment out the code relating to the use of Kaggle API since it was tested in a MAC OS and cannot guarantee reliability in other OS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# install the Kaggle API library\n",
    "#!pip install kaggle\n",
    "\n",
    "# download each ZIP file from the Kaggle website via the Kaggle API\n",
    "#!kaggle competitions download -c forest-cover-type-prediction -p ./data \n",
    "\n",
    "# define each downloaded file\n",
    "TRAIN_FILENAME = 'train.csv'\n",
    "TEST_FILENAME = 'test.csv'\n",
    "SAMPLE_SUBMISSION_FILENAME = 'sampleSubmission.csv'\n",
    "\n",
    "# define where the downloaded file will be stored\n",
    "DATAPATH = './data/'\n",
    "\n",
    "# unzip the files and load them as a panda DataFrame\n",
    "def get_data(filename, unzip=False):\n",
    "    '''Read CSV file (unzip or not) into a dataframe'''\n",
    "    if unzip:\n",
    "        zippath = DATAPATH + filename + '.zip'\n",
    "        return pd.read_csv(zippath, compression='zip', header=0, sep=',', quotechar='\"', index_col='Id')\n",
    "    \n",
    "    filepath = DATAPATH + filename\n",
    "    return pd.read_csv(filepath, header=0, sep=',', quotechar='\"', index_col='Id')\n",
    "\n",
    "train = get_data(TRAIN_FILENAME, unzip=False)\n",
    "test = get_data(TEST_FILENAME, unzip=False)\n",
    "sample = get_data(SAMPLE_SUBMISSION_FILENAME, unzip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the data\n",
    "train_data = train.drop('Cover_Type', axis=1)\n",
    "test_data = test\n",
    "\n",
    "# define the labels\n",
    "train_labels = train['Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define additional labels, not defined in the dataset\n",
    "cover_types = sorted(pd.unique(train['Cover_Type'])) # 1-7\n",
    "cover_labels = ['Spruce/Fir', 'Lodgepole Pine', 'Ponderosa Pine', 'Cottonwood/Willow', 'Aspen', 'Douglas-fir', 'Krummholz']\n",
    "wilderness_types = list(range(1,5)) # 1-4\n",
    "wilderness_labels = ['Rawah', 'Neota', 'Comanche', 'Cache la Poudre']\n",
    "soil_types = list(range(1,41)) # 1-40\n",
    "soil_labels = ['Cathedral family', \n",
    "               'Vanet', \n",
    "               'Haploborolis', \n",
    "               'Ratake family',\n",
    "               'Vanet family',\n",
    "               'Vanet - Wetmore families',\n",
    "               'Gothic family',\n",
    "               'Supervisor',\n",
    "               'Troutville family',\n",
    "               'Bullwark - Catamount families',\n",
    "               'Bullwark - Catamount families',\n",
    "               'Legault family',\n",
    "               'Catamount family',\n",
    "               'Pachic Argiborolis',\n",
    "               '',\n",
    "               'Cryaquolis',\n",
    "               'Gateview family',\n",
    "               'Rogert family',\n",
    "               'Typic Cryaquolis',\n",
    "               'Typic Cryaquepts',\n",
    "               'Typic Cryaquolls',\n",
    "               'Leighcan family',\n",
    "               'Leighcan family',\n",
    "               'Leighcan family',\n",
    "               'Leighcan family',\n",
    "               'Granile',\n",
    "               'Leighcan family',\n",
    "               'Leighcan family',\n",
    "               'Como - Legault families',\n",
    "               'Como family',\n",
    "               'Leighcan - Catamount families',\n",
    "               'Catamount family',\n",
    "               'Leighcan - Catamount families',\n",
    "               'Cryorthents',\n",
    "               'Cryumbrepts',\n",
    "               'Bross family',\n",
    "               'Cryumbrepts',\n",
    "               'Leighcan - Moran families',\n",
    "               'Moran family - Cryorthents',\n",
    "               'Moran family - Cryorthents'\n",
    "              ]\n",
    "soil_descriptions = ['Rock outcrop complex, extremely stony',\n",
    "                     'Ratake families complex, very stony',\n",
    "                     'Rock outcrop complex, rubbly',\n",
    "                     'Rock outcrop complex, rubbly',\n",
    "                     'Rock outcrop complex, rubbly',\n",
    "                     'Rock outcrop complex, stony',\n",
    "                     '',\n",
    "                     'Limber families complex',\n",
    "                     'very stony',\n",
    "                     'Rock outcrop complex, rubbly',\n",
    "                     'Rock land complex, rubbly',\n",
    "                     ' Rock land complex, stony',\n",
    "                     'Rock land - Bullwark family complex, rubbly',\n",
    "                     'Aquolis complex',\n",
    "                     '',\n",
    "                     'Cryoborolis complex',\n",
    "                     'Cryaquolis complex',\n",
    "                     'very stony',\n",
    "                     'Borohemists complex',\n",
    "                     'Typic Cryaquolls complex',\n",
    "                     'Leighcan family, till substratum complex',\n",
    "                     'till substratum, extremely bouldery',\n",
    "                     'till substratum, extremely bouldery',\n",
    "                     'extremely stony',\n",
    "                     'warm, extremely stony',\n",
    "                     'Catamount families complex, very stony',\n",
    "                     'Rock outcrop complex, extremely stony',\n",
    "                     'Rock outcrop complex, extremely stony',\n",
    "                     'complex, extremely stony',\n",
    "                     'Rock land - Legault family complex, extremely stony',\n",
    "                     'complex, extremely stony',\n",
    "                     'Rock outcrop - Leighcan family complex, extremely stony',\n",
    "                     'Rock outcrop complex, extremely stony',\n",
    "                     'Rock land complex, extremely stony',\n",
    "                     'Rock outcrop - Cryaquepts complex',\n",
    "                     'Rock land - Cryumbrepts complex, extremely stony',\n",
    "                     'Cryumbrepts - Cryorthents complex, extremely stony',\n",
    "                     'Cryaquolls complex, extremely stony',\n",
    "                     'Cryorthents - Leighcan family complex, extremely stony',\n",
    "                     'Cryorthents - Rock land complex, extremely stony'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='identify-the-train-labels'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the train labels\n",
    "\n",
    "There are 2,160 observations for each of the seven forest cover types. The classes are represented equally, which is great news, because we do not have to concern ourselves with misleading classification accuracy, a common problem that plagues an imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    2160\n",
       "6    2160\n",
       "5    2160\n",
       "4    2160\n",
       "3    2160\n",
       "2    2160\n",
       "1    2160\n",
       "Name: Cover_Type, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAD3CAYAAADfYKXJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naUkqzJCWpMJ+AnB4XymwXHdgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c543f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_labels.value_counts().plot(kind='barh')\n",
    "train_labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='identify-the-train-features'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the train features\n",
    "\n",
    "In the train dataset, there are 15,120 observations with 54 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15120, 54)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
       "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
       "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
       "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1',\n",
       "       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n",
       "       'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n",
       "       'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10',\n",
       "       'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14',\n",
       "       'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18',\n",
       "       'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22',\n",
       "       'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26',\n",
       "       'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n",
       "       'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34',\n",
       "       'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38',\n",
       "       'Soil_Type39', 'Soil_Type40'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the test dataset, there are 565,892 observations which includes the 54 features found in the train dataset. In other words, we have validated that the train dataset is a good dataset to use as it shares the same cartographic information as the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(565892, 54)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
       "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
       "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
       "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1',\n",
       "       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n",
       "       'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n",
       "       'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10',\n",
       "       'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14',\n",
       "       'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18',\n",
       "       'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22',\n",
       "       'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26',\n",
       "       'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n",
       "       'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34',\n",
       "       'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38',\n",
       "       'Soil_Type39', 'Soil_Type40'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test.shape)\n",
    "test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the features, it is interesting to note that we do not see longitude and latitude values, which means we cannot validate the cartographic information to the actual geographic location. The 54 features are summarized in the following table below:\n",
    "\n",
    "| Name                               | Measurement     | Description                                               |\n",
    "| ----------------------------------:| ---------------:| ---------------------------------------------------------:|\n",
    "| Elevation                          | meters          | Height above sea level                                    |\n",
    "| Aspect                             | degrees azimuth | Compass direction that a slope faces<br/>0: North, 90: East, 180: South, 270: West<br/>Potential influence on temperature and soil | \n",
    "| Slope                              | degrees         | Degree of incline of a surface<br/>In other words, maximum rate of change of elevation<br/>Has gradient and aspect as components                                                     | \n",
    "| Horizontal_Distance_To_Hydrology   | meters          | Horizontal Distance to the nearest surface water features | \n",
    "| Vertical_Distance_To_Hydrology     | meters          | Vertical Distance to the nearest surface water features   | \n",
    "| Horizontal_Distance_To_Roadways    | meters          | Horizontal distance to the nearest roadway                | \n",
    "| Horizontal_Distance_To_Fire_Points | meters          | Horizontal distance to the nearest wildfire ignition points | \n",
    "| Hillshade_9am                      | 0 (dark) to 255 (light) | Hillshade index at 9 AM, summer solstice | \n",
    "| Hillshade_Noon                     | 0 (dark) to 255 (light) | Hillshade index at 12 PM, summer solstice | \n",
    "| Hillshade_3pm                      | 0 (dark) to 255 (light) | Hillshade index at 3 PM, summer solstice | \n",
    "| Wilderness_Area (4 binary columns) | 0 (absent) or 1 (present) | Wilderness area designation<br/>1: Rawah, 2: Neota, 3: Comanche, 4: Cache la Poudre | \n",
    "| Soil_Type (40 binary columns)      | 0 (absent) or 1 (present) | Soil type designation |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feature-engineering'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='models'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Base Case\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# 1. Logistic Regression\n",
    "lr = LogisticRegression(multi_class='multinomial', penalty='l2', solver='newton-cg')\n",
    "lr.fit(s_train_data, s_train_labels)\n",
    "accuracies = []\n",
    "for i in range(1, 10):\n",
    "    pred_dev_labels = lr.predict(s_dev_data)\n",
    "    accuracies.append(accuracy_score(s_dev_labels, pred_dev_labels))\n",
    "mean_accuracies = sum(accuracies)/len(accuracies)\n",
    "output_bc[0] = mean_accuracies\n",
    "mean_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Base Case with Feature Engineering\n",
    "# --------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ensemble-models'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
