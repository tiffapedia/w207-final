{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W207 Summer 2018 Final Project \n",
    "---\n",
    "\n",
    "**Authors:** Divya Gorantla, Ram Iyer, Tiffany Jaya, Steve Sanders <br/>\n",
    "**Date:** 5 August 2018\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Exploratory Data Analysis](#eda)\n",
    "  1. [Load libraries](#load-libraries)\n",
    "  2. [Load data](#load-data)\n",
    "  3. [Identify the train labels](#identify-the-train-labels)\n",
    "  4. [Identify the train features](#identify-the-train-features)\n",
    "  5. [Address concerns about the datasets](#address-concerns-about-the-datasets)\n",
    "3. [Feature Engineering](#feature-engineering)\n",
    "4. [Models](#models)\n",
    "  1. [Model Results](#model-results)\n",
    "5. [Ensemble Models](#ensemble-models)\n",
    "  1. [Ensemble Results](#ensemble-results)\n",
    "6. [Stack Models](#stack-models)\n",
    "  1. [Stack Results](#stack-results)\n",
    "7. [Conclusion](#conclusion)\n",
    "8. [References](#references)\n",
    "9. [Appendix](#appendix)\n",
    "  1. [Cross Validation](#appendix-cv)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='introduction'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Our goal in this project is to classify an observed 30 x 30 meter land into one of the seven forest cover types found in the Roosevelt National Forest of Northern Colarado: \n",
    "\n",
    "| Forest Cover Type  | Tree   | Leaf  | \n",
    "| ------------------ |:------:| -----:| \n",
    "| Spruce/Fir         | <img src='./img/spruce-tree.jpg' alt='Spruce tree' height='65px' width='65px'/><br /><img src='./img/fir-tree.jpg' alt='Fir tree' height='65px' width='65px'/> | <img src='./img/spruce.jpg' alt='Spruce leaf' height='65px' width='65px'/><br /><img src='./img/fir.jpg' alt='Fir leaf' height='65px' width='65px'/> | \n",
    "| Lodgepole Pine     | <img src='./img/lodgepole-pine-tree.jpg' alt='Lodgepole Pine tree' height='65px' width='65px'/> | <img src='./img/lodgepole-pine.jpg' alt='Lodgepole Pine leaf' height='65px' width='65px'/> | \n",
    "| Ponderosa Pine     | <img src='./img/ponderosa-pine-tree.jpg' alt='Ponderosa Pine tree' height='65px' width='65px'/> | <img src='./img/ponderosa-pine.jpg' alt='Ponderosa Pine leaf' height='65px' width='65px'/> |\n",
    "| Cottonwood/Willow  | <img src='./img/cottonwood-tree.jpg' alt='Cottonwood tree' height='65px' width='65px'/><br /><img src='./img/willow-tree.jpg' alt='Willow tree' height='65px' width='65px'/> | <img src='./img/cottonwood.jpg' alt='Cottonwood leaf' height='65px' width='65px'/><br /><img src='./img/willow.jpg' alt='Willow leaf' height='65px' width='65px'/> |\n",
    "| Aspen              | <img src='./img/aspen-tree.jpg' alt='Aspen tree' height='65px' width='65px'/> | <img src='./img/aspen.jpg' alt='Aspen leaf' height='65px' width='65px'/> | \n",
    "| Douglas-Fir        | <img src='./img/douglas-fir-tree.jpg' alt='Douglas-Fir tree' height='65px' width='65px'/> | <img src='./img/douglas-fir.jpg' alt='Douglas-Fir leaf' height='65px' width='65px'/> | \n",
    "| Krummholz <br />(stunted trees) | <img src='./img/krummholz-tree.jpg' alt='Krummholz tree' height='65px' width='65px'/> | |\n",
    "\n",
    "Fortunately for us, 15,120 of these observations have been labeled to their respective forest cover types. We can then use this labeled dataset to train several different models and compare which model can best accurately classify the forest cover type based on just the cartographic information. \n",
    "\n",
    "What we have found is that random forest classifier perform best among the three models we have tested with an accuracy score of 77.2%.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "All cartographic information that we use as features to determine the forest cover type has been collected by the US Geological Survey (USGS) and US Forest Service (USFS). The associating labels were derived separately by the USFS Region 2 Resource Information System. We download them from the Kaggle website via the Kaggle API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load-libraries'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# general libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plot libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# preprocessing (aka feature engineering)\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# model definition\n",
    "from sklearn import svm as SVM\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# model metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# define the random_state\n",
    "random_state = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load-data'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "We used the Kaggle API to download the data directly from the Kaggle website. \n",
    "\n",
    "To use the Kaggle API, please follow these instructions:\n",
    "\n",
    "1. Login to your Kaggle account\n",
    "2. Select 'My account'\n",
    "3. Select 'Create New API Token'\n",
    "4. Place the token 'kaggle.json' into ~/.kaggle\n",
    "\n",
    "We decided to comment out the code relating to the use of Kaggle API since it was tested in a MAC OS and cannot guarantee reliability in other OS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# install the Kaggle API library\n",
    "#!pip install kaggle\n",
    "\n",
    "# download each ZIP file from the Kaggle website via the Kaggle API\n",
    "#!kaggle competitions download -c forest-cover-type-prediction -p ./data \n",
    "\n",
    "# define each downloaded file\n",
    "TRAIN_FILENAME = 'train.csv'\n",
    "TEST_FILENAME = 'test.csv'\n",
    "SAMPLE_SUBMISSION_FILENAME = 'sampleSubmission.csv'\n",
    "\n",
    "# define where the downloaded file will be stored\n",
    "DATAPATH = './data/'\n",
    "\n",
    "# unzip the files and load them as a panda DataFrame\n",
    "def get_data(filename, unzip=False):\n",
    "    '''Read CSV file (unzip or not) into a dataframe'''\n",
    "    if unzip:\n",
    "        zippath = DATAPATH + filename + '.zip'\n",
    "        return pd.read_csv(zippath, compression='zip', header=0, sep=',', quotechar='\"', index_col='Id')\n",
    "    \n",
    "    filepath = DATAPATH + filename\n",
    "    return pd.read_csv(filepath, header=0, sep=',', quotechar='\"', index_col='Id')\n",
    "\n",
    "train = get_data(TRAIN_FILENAME, unzip=False)\n",
    "test = get_data(TEST_FILENAME, unzip=False)\n",
    "sample = get_data(SAMPLE_SUBMISSION_FILENAME, unzip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the data\n",
    "train_data = train.drop('Cover_Type', axis=1)\n",
    "test_data = test\n",
    "\n",
    "# define the labels\n",
    "train_labels = train['Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define additional labels, not defined in the dataset\n",
    "cover_types = sorted(pd.unique(train['Cover_Type'])) # 1-7\n",
    "cover_labels = ['Spruce/Fir', 'Lodgepole Pine', 'Ponderosa Pine', 'Cottonwood/Willow', 'Aspen', 'Douglas-fir', 'Krummholz']\n",
    "wilderness_types = list(range(1,5)) # 1-4\n",
    "wilderness_labels = ['Rawah', 'Neota', 'Comanche', 'Cache la Poudre']\n",
    "soil_types = list(range(1,41)) # 1-40\n",
    "soil_labels = ['Cathedral family', \n",
    "               'Vanet', \n",
    "               'Haploborolis', \n",
    "               'Ratake family',\n",
    "               'Vanet family',\n",
    "               'Vanet - Wetmore families',\n",
    "               'Gothic family',\n",
    "               'Supervisor',\n",
    "               'Troutville family',\n",
    "               'Bullwark - Catamount families',\n",
    "               'Bullwark - Catamount families',\n",
    "               'Legault family',\n",
    "               'Catamount family',\n",
    "               'Pachic Argiborolis',\n",
    "               '',\n",
    "               'Cryaquolis',\n",
    "               'Gateview family',\n",
    "               'Rogert family',\n",
    "               'Typic Cryaquolis',\n",
    "               'Typic Cryaquepts',\n",
    "               'Typic Cryaquolls',\n",
    "               'Leighcan family',\n",
    "               'Leighcan family',\n",
    "               'Leighcan family',\n",
    "               'Leighcan family',\n",
    "               'Granile',\n",
    "               'Leighcan family',\n",
    "               'Leighcan family',\n",
    "               'Como - Legault families',\n",
    "               'Como family',\n",
    "               'Leighcan - Catamount families',\n",
    "               'Catamount family',\n",
    "               'Leighcan - Catamount families',\n",
    "               'Cryorthents',\n",
    "               'Cryumbrepts',\n",
    "               'Bross family',\n",
    "               'Cryumbrepts',\n",
    "               'Leighcan - Moran families',\n",
    "               'Moran family - Cryorthents',\n",
    "               'Moran family - Cryorthents'\n",
    "              ]\n",
    "soil_descriptions = ['Rock outcrop complex, extremely stony',\n",
    "                     'Ratake families complex, very stony',\n",
    "                     'Rock outcrop complex, rubbly',\n",
    "                     'Rock outcrop complex, rubbly',\n",
    "                     'Rock outcrop complex, rubbly',\n",
    "                     'Rock outcrop complex, stony',\n",
    "                     '',\n",
    "                     'Limber families complex',\n",
    "                     'very stony',\n",
    "                     'Rock outcrop complex, rubbly',\n",
    "                     'Rock land complex, rubbly',\n",
    "                     ' Rock land complex, stony',\n",
    "                     'Rock land - Bullwark family complex, rubbly',\n",
    "                     'Aquolis complex',\n",
    "                     '',\n",
    "                     'Cryoborolis complex',\n",
    "                     'Cryaquolis complex',\n",
    "                     'very stony',\n",
    "                     'Borohemists complex',\n",
    "                     'Typic Cryaquolls complex',\n",
    "                     'Leighcan family, till substratum complex',\n",
    "                     'till substratum, extremely bouldery',\n",
    "                     'till substratum, extremely bouldery',\n",
    "                     'extremely stony',\n",
    "                     'warm, extremely stony',\n",
    "                     'Catamount families complex, very stony',\n",
    "                     'Rock outcrop complex, extremely stony',\n",
    "                     'Rock outcrop complex, extremely stony',\n",
    "                     'complex, extremely stony',\n",
    "                     'Rock land - Legault family complex, extremely stony',\n",
    "                     'complex, extremely stony',\n",
    "                     'Rock outcrop - Leighcan family complex, extremely stony',\n",
    "                     'Rock outcrop complex, extremely stony',\n",
    "                     'Rock land complex, extremely stony',\n",
    "                     'Rock outcrop - Cryaquepts complex',\n",
    "                     'Rock land - Cryumbrepts complex, extremely stony',\n",
    "                     'Cryumbrepts - Cryorthents complex, extremely stony',\n",
    "                     'Cryaquolls complex, extremely stony',\n",
    "                     'Cryorthents - Leighcan family complex, extremely stony',\n",
    "                     'Cryorthents - Rock land complex, extremely stony'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='identify-the-train-labels'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the train labels\n",
    "\n",
    "There are 2,160 observations for each of the seven forest cover types. The classes are represented equally, which is great news, because we do not have to concern ourselves with misleading classification accuracy, a common problem that plagues an imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    2160\n",
       "6    2160\n",
       "5    2160\n",
       "4    2160\n",
       "3    2160\n",
       "2    2160\n",
       "1    2160\n",
       "Name: Cover_Type, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdkAAAFJCAYAAADXIVdBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCwBJ/hcQIIJzbkk7KgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e3df630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_labels.value_counts().plot(kind='barh')\n",
    "train_labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='identify-the-train-features'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the train features\n",
    "\n",
    "In the train dataset, there are 15,120 observations with 54 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15120, 54)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
       "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
       "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
       "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1',\n",
       "       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n",
       "       'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n",
       "       'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10',\n",
       "       'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14',\n",
       "       'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18',\n",
       "       'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22',\n",
       "       'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26',\n",
       "       'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n",
       "       'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34',\n",
       "       'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38',\n",
       "       'Soil_Type39', 'Soil_Type40'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the test dataset, there are 565,892 observations which includes the 54 features found in the train dataset. In other words, we have validated that the train dataset is a good dataset to use as it shares the same cartographic information as the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(565892, 54)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
       "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
       "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
       "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1',\n",
       "       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n",
       "       'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n",
       "       'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10',\n",
       "       'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14',\n",
       "       'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18',\n",
       "       'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22',\n",
       "       'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26',\n",
       "       'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n",
       "       'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34',\n",
       "       'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38',\n",
       "       'Soil_Type39', 'Soil_Type40'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test.shape)\n",
    "test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the features, it is interesting to note that we do not see longitude and latitude values, which means we cannot validate the cartographic information to the actual geographic location. The 54 features are summarized in the following table below:\n",
    "\n",
    "| Name                               | Measurement     | Description                                               |\n",
    "| ----------------------------------:| ---------------:| ---------------------------------------------------------:|\n",
    "| Elevation                          | meters          | Height above sea level                                    |\n",
    "| Aspect                             | degrees azimuth | Compass direction that a slope faces<br/>0: North, 90: East, 180: South, 270: West<br/>Potential influence on temperature and soil | \n",
    "| Slope                              | degrees         | Degree of incline of a surface<br/>In other words, maximum rate of change of elevation<br/>Has gradient and aspect as components                                                     | \n",
    "| Horizontal_Distance_To_Hydrology   | meters          | Horizontal Distance to the nearest surface water features | \n",
    "| Vertical_Distance_To_Hydrology     | meters          | Vertical Distance to the nearest surface water features   | \n",
    "| Horizontal_Distance_To_Roadways    | meters          | Horizontal distance to the nearest roadway                | \n",
    "| Horizontal_Distance_To_Fire_Points | meters          | Horizontal distance to the nearest wildfire ignition points | \n",
    "| Hillshade_9am                      | 0 (dark) to 255 (light) | Hillshade index at 9 AM, summer solstice | \n",
    "| Hillshade_Noon                     | 0 (dark) to 255 (light) | Hillshade index at 12 PM, summer solstice | \n",
    "| Hillshade_3pm                      | 0 (dark) to 255 (light) | Hillshade index at 3 PM, summer solstice | \n",
    "| Wilderness_Area (4 binary columns) | 0 (absent) or 1 (present) | Wilderness area designation<br/>1: Rawah, 2: Neota, 3: Comanche, 4: Cache la Poudre | \n",
    "| Soil_Type (40 binary columns)      | 0 (absent) or 1 (present) | Soil type designation |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feature-engineering'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a copy of the train data to be modified\n",
    "fe_train_data = train_data.copy()\n",
    "fe_train_labels = train_labels.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Normalize Hillshade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFJCAYAAABU5W56AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHy9JREFUeJzt3X9M3PXhx/HXwQHS42hLgolJhxbtJXaGCHTUxoHWGJnJ\nvvmyqlfvGlyjNStr9Au6Sn9RXPxR+W7cHIvEX11MDg9GpvthXPZD2sEmjFSmdkOZkXRdrD9yIsa7\nU6A/Pt8/vuE2bMtd27vjzd3z8Vfvfe/rvV8c/bzu/YF+zmZZliUAAGCkrIVeAAAAODuKGgAAg1HU\nAAAYjKIGAMBgFDUAAAajqAEAMJh9oRdwJsFg6IIev3z5Ek1Ofp6g1ZgrU3JKZE1HmZJTypysmZJT\nSnzW4mLnWe9Lyx213Z690EtIiUzJKZE1HWVKTilzsmZKTim1WdOyqAEASBcUNQAABqOoAQAwGEUN\nAIDBKGoAAAwW879nHT9+XDt27NCxY8eUlZWlhx56SHa7XTt27JDNZtOqVavU2tqqrKws9fb2qqen\nR3a7XQ0NDVq/fr2mpqa0fft2TUxMyOFwqK2tTUVFRanIBgDAohdzR93f368TJ06op6dH27Zt0+OP\nP659+/apsbFRgUBAlmWpr69PwWBQfr9fPT092r9/v3w+n2ZmZtTd3S2Xy6VAIKC6ujp1dnamIhcA\nAGkhZlGvXLlSJ0+e1KlTpxQOh2W32zU6OqqqqipJUk1NjQYHB3X48GGVl5crNzdXTqdTJSUlGhsb\n08jIiKqrq6Nzh4aGkpsIAIA0EvPU95IlS3Ts2DHdfPPNmpyc1JNPPqlDhw7JZrNJkhwOh0KhkMLh\nsJzOf19ZxeFwKBwOzxmfnRvL8uVLLvg/k893lZd0kik5JbKmo0zJKWVO1kzJKaUua8yifu655/T1\nr39d999/vz744AN9+9vf1vHjx6P3RyIRFRYWqqCgQJFIZM640+mcMz47N5YLvSxbcbHzgi9Duhhk\nSk6JrOkoU3JKmZM1U3JKic96QZcQLSwsjO6Ily5dqhMnTmj16tUaHh6WJA0MDGjNmjUqKyvTyMiI\npqenFQqFND4+LpfLpYqKCvX390fnVlZWJiITAAAZIeaOevPmzdq1a5e8Xq+OHz+upqYmXXXVVWpp\naZHP51Npaalqa2uVnZ2t+vp6eb1eWZalpqYm5eXlyePxqLm5WR6PRzk5OWpvb09FLgAA0oLNsixr\noRfxZRd6OiFTTr9kSk6JrIvBtgMPxD33iRv+d9HmPB+ZkjVTckqGnfoGAAALh6IGAMBgFDUAAAaj\nqAEAMBhFDQCAwShqAAAMRlEDAGAwihoAAINR1AAAGIyiBgDAYBQ1AAAGo6gBADAYRQ0AgMEoagAA\nDEZRAwBgMIoaAACDUdQAABiMogYAwGAUNQAABqOoAQAwGEUNAIDBKGoAAAxGUQMAYDCKGgAAg1HU\nAAAYjKIGAMBgFDUAAAajqAEAMJg91oQXX3xRv/jFLyRJ09PTevvttxUIBPToo4/KZrNp1apVam1t\nVVZWlnp7e9XT0yO73a6GhgatX79eU1NT2r59uyYmJuRwONTW1qaioqKkBwMAIB3E3FFv2LBBfr9f\nfr9fX/3qV7Vnzx498cQTamxsVCAQkGVZ6uvrUzAYlN/vV09Pj/bv3y+fz6eZmRl1d3fL5XIpEAio\nrq5OnZ2dqcgFAEBaiPvU99/+9je9++672rhxo0ZHR1VVVSVJqqmp0eDgoA4fPqzy8nLl5ubK6XSq\npKREY2NjGhkZUXV1dXTu0NBQcpIAAJCGYp76nvXUU09p27ZtkiTLsmSz2SRJDodDoVBI4XBYTqcz\nOt/hcCgcDs8Zn50by/LlS2S3Z59TkC8rLnbGnpQGMiWnRNZ0Mpsv3XP+p0zJmik5pdRljauoP/vs\nMx05ckTXXHONJCkr698b8UgkosLCQhUUFCgSicwZdzqdc8Zn58YyOfn5OYX4suJip4LB2G8IFrtM\nySmRNd0Eg6GMyDkrU7JmSk4p8VnnK/24Tn0fOnRI69ati95evXq1hoeHJUkDAwNas2aNysrKNDIy\nounpaYVCIY2Pj8vlcqmiokL9/f3RuZWVlReSBQCAjBLXjvrIkSNasWJF9HZzc7NaWlrk8/lUWlqq\n2tpaZWdnq76+Xl6vV5ZlqampSXl5efJ4PGpubpbH41FOTo7a29uTFgYAgHQTV1Fv2bJlzu2VK1eq\nq6vrtHlut1tut3vOWH5+vjo6Oi5giQAAZC4ueAIAgMEoagAADEZRAwBgMIoaAACDUdQAABiMogYA\nwGAUNQAABqOoAQAwGEUNAIDBKGoAAAxGUQMAYDCKGgAAg1HUAAAYjKIGAMBgFDUAAAaL6/OoAcBU\ndz52IO65P91xQxJXAiQHO2oAAAxGUQMAYDCKGgAAg1HUAAAYjKIGAMBgFDUAAAajqAEAMBhFDQCA\nwShqAAAMRlEDAGAwihoAAINR1AAAGCyuD+V46qmndODAAR0/flwej0dVVVXasWOHbDabVq1apdbW\nVmVlZam3t1c9PT2y2+1qaGjQ+vXrNTU1pe3bt2tiYkIOh0NtbW0qKipKdi4AANJCzB318PCwXn/9\ndXV3d8vv9+vDDz/Uvn371NjYqEAgIMuy1NfXp2AwKL/fr56eHu3fv18+n08zMzPq7u6Wy+VSIBBQ\nXV2dOjs7U5ELAIC0ELOo//znP8vlcmnbtm3aunWrrr/+eo2OjqqqqkqSVFNTo8HBQR0+fFjl5eXK\nzc2V0+lUSUmJxsbGNDIyourq6ujcoaGh5CYCACCNxDz1PTk5qffff19PPvmk3nvvPTU0NMiyLNls\nNkmSw+FQKBRSOByW0+mMPs7hcCgcDs8Zn50by/LlS2S3Z59vJklScbEz9qQ0kCk5JbKmk9l8qc65\nkF/XdH9NZ2VKTil1WWMW9bJly1RaWqrc3FyVlpYqLy9PH374YfT+SCSiwsJCFRQUKBKJzBl3Op1z\nxmfnxjI5+fn5ZIkqLnYqGIz9hmCxy5ScElkXyp2PHYh7bn5V/H9vMBhakJwL9XU16TVNpkzJKSU+\n63ylH/PUd2Vlpf70pz/Jsix99NFH+uKLL7Ru3ToNDw9LkgYGBrRmzRqVlZVpZGRE09PTCoVCGh8f\nl8vlUkVFhfr7+6NzKysrExQLAID0F3NHvX79eh06dEi33nqrLMvS3r17tWLFCrW0tMjn86m0tFS1\ntbXKzs5WfX29vF6vLMtSU1OT8vLy5PF41NzcLI/Ho5ycHLW3t6ciFwAAaSGu/571wAMPnDbW1dV1\n2pjb7Zbb7Z4zlp+fr46OjvNcHgAAmY0LngAAYDCKGgAAg1HUAAAYjKIGAMBgFDUAAAajqAEAMBhF\nDQCAwShqAAAMRlEDAGAwihoAAINR1AAAGIyiBgDAYBQ1AAAGo6gBADAYRQ0AgMEoagAADEZRAwBg\nMPtCLwAAUmXbgQfOaf4TN/xvklYCxI8dNQAABqOoAQAwGEUNAIDBKGoAAAxGUQMAYDCKGgAAg1HU\nAAAYjKIGAMBgFDUAAAajqAEAMFhclxD91re+pYKCAknSihUrtHXrVu3YsUM2m02rVq1Sa2ursrKy\n1Nvbq56eHtntdjU0NGj9+vWamprS9u3bNTExIYfDoba2NhUVFSU1FAAA6SJmUU9PT8uyLPn9/ujY\n1q1b1djYqLVr12rv3r3q6+vT1VdfLb/frxdeeEHT09Pyer269tpr1d3dLZfLpXvuuUcvv/yyOjs7\ntWfPnqSGAgAgXcQ89T02NqYvvvhCd955p+644w698cYbGh0dVVVVlSSppqZGg4ODOnz4sMrLy5Wb\nmyun06mSkhKNjY1pZGRE1dXV0blDQ0PJTQQAQBqJuaO+6KKLdNddd+m2227TP//5T919992yLEs2\nm02S5HA4FAqFFA6H5XQ6o49zOBwKh8NzxmfnxrJ8+RLZ7dnnm0mSVFzsjD0pDWRKToms6WQ2n+k5\nE7k+07MmSqbklFKXNWZRr1y5UpdeeqlsNptWrlypZcuWaXR0NHp/JBJRYWGhCgoKFIlE5ow7nc45\n47NzY5mc/Px8skQVFzsVDMZ+Q7DYZUpOiazpJhgMLYqciVrfYsiaCJmSU0p81vlKP+ap75///Od6\n7LHHJEkfffSRwuGwrr32Wg0PD0uSBgYGtGbNGpWVlWlkZETT09MKhUIaHx+Xy+VSRUWF+vv7o3Mr\nKysTkQkAgIwQc0d96623aufOnfJ4PLLZbHr00Ue1fPlytbS0yOfzqbS0VLW1tcrOzlZ9fb28Xq8s\ny1JTU5Py8vLk8XjU3Nwsj8ejnJwctbe3pyIXAABpIWZR5+bmnrFcu7q6Thtzu91yu91zxvLz89XR\n0XEBSwQAIHNxwRMAAAxGUQMAYDCKGgAAg1HUAAAYjKIGAMBgFDUAAAajqAEAMBhFDQCAwShqAAAM\nRlEDAGAwihoAAINR1AAAGIyiBgDAYBQ1AAAGo6gBADAYRQ0AgMEoagAADEZRAwBgMIoaAACDUdQA\nABiMogYAwGAUNQAABqOoAQAwGEUNAIDBKGoAAAxGUQMAYDCKGgAAg1HUAAAYLK6inpiY0HXXXafx\n8XEdPXpUHo9HXq9Xra2tOnXqlCSpt7dXGzZskNvt1sGDByVJU1NTuueee+T1enX33Xfrk08+SV4S\nAADSUMyiPn78uPbu3auLLrpIkrRv3z41NjYqEAjIsiz19fUpGAzK7/erp6dH+/fvl8/n08zMjLq7\nu+VyuRQIBFRXV6fOzs6kBwIAIJ3ELOq2tjbdfvvtuvjiiyVJo6OjqqqqkiTV1NRocHBQhw8fVnl5\nuXJzc+V0OlVSUqKxsTGNjIyouro6OndoaCiJUQAASD/2+e588cUXVVRUpOrqaj399NOSJMuyZLPZ\nJEkOh0OhUEjhcFhOpzP6OIfDoXA4PGd8dm48li9fIrs9+7wCzSoudsaelAYyJadE1nQym8/0nIlc\nn+lZEyVTckqpyzpvUb/wwguy2WwaGhrS22+/rebm5jk/Z45EIiosLFRBQYEikciccafTOWd8dm48\nJic/P58sUcXFTgWD8b0pWMwyJadE1nQTDIYWRc5ErW8xZE2ETMkpJT7rfKU/76nv559/Xl1dXfL7\n/bryyivV1tammpoaDQ8PS5IGBga0Zs0alZWVaWRkRNPT0wqFQhofH5fL5VJFRYX6+/ujcysrKxMW\nCgCATDDvjvpMmpub1dLSIp/Pp9LSUtXW1io7O1v19fXyer2yLEtNTU3Ky8uTx+NRc3OzPB6PcnJy\n1N7enowMAACkrbiL2u/3R//c1dV12v1ut1tut3vOWH5+vjo6Oi5geQAAZDYueAIAgMEoagAADEZR\nAwBgMIoaAACDUdQAABiMogYAwGAUNQAABqOoAQAwGEUNAIDBKGoAAAxGUQMAYDCKGgAAg1HUAAAY\njKIGAMBgFDUAAAajqAEAMBhFDQCAwewLvQAAmeedLZv1TpxzXc8+l8ylAMZjRw0AgMEoagAADEZR\nAwBgMIoaAACDUdQAABiMogYAwGAUNQAABqOoAQAwGEUNAIDBKGoAAAwW8xKiJ0+e1J49e3TkyBHZ\nbDZ9//vfV15ennbs2CGbzaZVq1aptbVVWVlZ6u3tVU9Pj+x2uxoaGrR+/XpNTU1p+/btmpiYkMPh\nUFtbm4qKilKRDQCARS/mjvrgwYOSpJ6eHjU2NupHP/qR9u3bp8bGRgUCAVmWpb6+PgWDQfn9fvX0\n9Gj//v3y+XyamZlRd3e3XC6XAoGA6urq1NnZmfRQAACki5g76htvvFHXX3+9JOn9999XYWGhBgcH\nVVVVJUmqqanRq6++qqysLJWXlys3N1e5ubkqKSnR2NiYRkZGtGXLluhcihoAgPjF9elZdrtdzc3N\n+sMf/qCOjg69+uqrstlskiSHw6FQKKRwOCyn0xl9jMPhUDgcnjM+OzeW5cuXyG7PPp88UcXFztiT\n0kCm5JTImqkW8muRyOfOlNc0U3JKqcsa98dctrW16Xvf+57cbremp6ej45FIRIWFhSooKFAkEpkz\n7nQ654zPzo1lcvLzc8lwmuJip4LB2G8IFrtMySmRNZMt5Nfi1f++Je65830cZ6a8ppmSU0p81vlK\nP+bPqH/5y1/qqaeekiTl5+fLZrPpqquu0vDwsCRpYGBAa9asUVlZmUZGRjQ9Pa1QKKTx8XG5XC5V\nVFSov78/OreysjIRmQAAyAgxd9Q33XSTdu7cqU2bNunEiRPatWuXLr/8crW0tMjn86m0tFS1tbXK\nzs5WfX29vF6vLMtSU1OT8vLy5PF41NzcLI/Ho5ycHLW3t6ciFwAAaSFmUS9ZskQ//vGPTxvv6uo6\nbcztdsvtds8Zy8/PV0dHxwUsEQCAzMUFTwAAMBhFDQCAwShqAAAMRlEDAGAwihoAAINR1AAAGIyi\nBgDAYBQ1AAAGo6gBADAYRQ0AgMEoagAADEZRAwBgMIoaAACDUdQAABiMogYAwGAUNQAABqOoAQAw\nmH2hFwAgsd7Zsjnuua5nn0vaOgAkBjtqAAAMRlEDAGAwihoAAINR1AAAGIyiBgDAYBQ1AAAGo6gB\nADAYRQ0AgMEoagAADEZRAwBgsHkvIXr8+HHt2rVLx44d08zMjBoaGnTFFVdox44dstlsWrVqlVpb\nW5WVlaXe3l719PTIbreroaFB69ev19TUlLZv366JiQk5HA61tbWpqKgoVdkAAFj05t1R//rXv9ay\nZcsUCAT07LPP6qGHHtK+ffvU2NioQCAgy7LU19enYDAov9+vnp4e7d+/Xz6fTzMzM+ru7pbL5VIg\nEFBdXZ06OztTlQsAgLQw7476G9/4hmprayVJlmUpOztbo6OjqqqqkiTV1NTo1VdfVVZWlsrLy5Wb\nm6vc3FyVlJRobGxMIyMj2rJlS3QuRQ38252PHYh77k933JDElQAw2bw7aofDoYKCAoXDYd17771q\nbGyUZVmy2WzR+0OhkMLhsJxO55zHhcPhOeOzcwEAQPxifszlBx98oG3btsnr9eq//uu/9IMf/CB6\nXyQSUWFhoQoKChSJROaMO53OOeOzc+OxfPkS2e3Z55pljuJiZ+xJaSBTckqZlfXLziX7O0n6exfK\nYlijFHudycrx6n/fEvfca3/1QlLW8J8Wy+uVCKnKOm9Rf/zxx7rzzju1d+9erVu3TpK0evVqDQ8P\na+3atRoYGNA111yjsrIyPf7445qentbMzIzGx8flcrlUUVGh/v5+lZWVaWBgQJWVlXEtanLy8wsK\nVVzsVDCY/rv3TMkpZVbWM0lW9sXwNV0Ma5TmX6cp37/JXoMpOVMh0VnnK/15i/rJJ5/UZ599ps7O\nzujPl3fv3q2HH35YPp9PpaWlqq2tVXZ2turr6+X1emVZlpqampSXlyePx6Pm5mZ5PB7l5OSovb09\nYaEAAMgE8xb1nj17tGfPntPGu7q6Thtzu91yu91zxvLz89XR0XGBSwQAIHNxwRMAAAxGUQMAYDCK\nGgAAg1HUAAAYjKIGAMBgFDUAAAajqAEAMFjMS4gCWHjbDjwQ99z/SeI6AKQeO2oAAAxGUQMAYDBO\nfQNxemfL5rjnup59LmnrAJBZ2FEDAGAwihoAAINR1AAAGIyiBgDAYBQ1AAAGo6gBADAYRQ0AgMEo\nagAADEZRAwBgMIoaAACDUdQAABiMogYAwGAUNQAABqOoAQAwGEUNAIDBKGoAAAxGUQMAYDCKGgAA\ng8VV1G+++abq6+slSUePHpXH45HX61Vra6tOnTolSert7dWGDRvkdrt18OBBSdLU1JTuueceeb1e\n3X333frkk0+SFAMAgPQUs6ifeeYZ7dmzR9PT05Kkffv2qbGxUYFAQJZlqa+vT8FgUH6/Xz09Pdq/\nf798Pp9mZmbU3d0tl8ulQCCguro6dXZ2Jj0QAADpJGZRl5SU6Cc/+Un09ujoqKqqqiRJNTU1Ghwc\n1OHDh1VeXq7c3Fw5nU6VlJRobGxMIyMjqq6ujs4dGhpKUgwAANKTPdaE2tpavffee9HblmXJZrNJ\nkhwOh0KhkMLhsJxOZ3SOw+FQOByeMz47Nx7Lly+R3Z59TkG+rLjYGXtSGsiUnNLCZ33nHOYu9Frj\ntRjWuRjWKMVeZ7JymPZ9uVher0RIVdaYRf1lWVn/3oRHIhEVFhaqoKBAkUhkzrjT6ZwzPjs3HpOT\nn5/rsuYoLnYqGIzvTcFilik5pcWXdbGsdTGsczGsUZp/naZ8/yZ7DabkTIVEZ52v9M+5qFevXq3h\n4WGtXbtWAwMDuuaaa1RWVqbHH39c09PTmpmZ0fj4uFwulyoqKtTf36+ysjINDAyosrLygoIgfb2z\nZfP89//Hn13PPpfMpQBIsFj/vv8T/75Pd85F3dzcrJaWFvl8PpWWlqq2tlbZ2dmqr6+X1+uVZVlq\nampSXl6ePB6Pmpub5fF4lJOTo/b29mRkAAAgbcVV1CtWrFBvb68kaeXKlerq6jptjtvtltvtnjOW\nn5+vjo6OBCwTAIDMxAVPAAAwGEUNAIDBKGoAAAxGUQMAYDCKGgAAg1HUAAAYjKIGAMBgFDUAAAaj\nqAEAMNg5X0IUMN2djx2Ie+5Pd9yQxJUAwIVjRw0AgMEoagAADEZRAwBgMIoaAACD8ctkae5cPrBd\n4kPbAcA07KgBADAYRQ0AgMEoagAADEZRAwBgMIoaAACDUdQAABiMogYAwGAUNQAABuOCJwAA6Nwu\nEFX8qxeSt5AvoagvwLm8qFzxCwBwPihqZLRtBx6Ie+7/JHEdAHA2/IwaAACDUdQAABgs6ae+T506\npQcffFD/+Mc/lJubq4cffliXXnppsp8WSXLnYwfinvvTHTckcSUAkBmSvqN+5ZVXNDMzo5/97Ge6\n//779dhjjyX7KQEASBtJ31GPjIyourpaknT11Vfr73//e7KfEobgF7UA4MLZLMuykvkEu3fv1k03\n3aTrrrtOknT99dfrlVdekd3OL5wDABBL0k99FxQUKBKJRG+fOnWKkgYAIE5JL+qKigoNDAxIkt54\n4w25XK5kPyUAAGkj6ae+Z3/r+5133pFlWXr00Ud1+eWXJ/MpAQBIG0kvagAAcP644AkAAAajqAEA\nMNiiKOpTp05p79692rhxo+rr63X06NE59x84cEC33HKLNm7cqN7e3nkfc/ToUXk8Hnm9XrW2turU\nqVMpz3M2icz59ttvy+v1qr6+XnfddZc+/vjjlOeZTyKzznrppZe0cePGlGWIRyJzTkxMqKGhQZs2\nbdLtt9+uf/3rXynPM59Ef/+63W55PB7t3LnTqH+n0vllnfXmm2+qvr4+ejvdjkmzvpwzHY9Js76c\ndVbCjknWIvC73/3Oam5utizLsl5//XVr69at0ftmZmasG2+80fr000+t6elpa8OGDVYwGDzrY77z\nne9Yf/nLXyzLsqyWlhbr97//fYrTnF0ic27atMl66623LMuyrO7ubuvRRx9NcZr5JTKrZVnW6Oio\ndccdd1i33XZbaoPEkMiczc3N1ssvv2xZlmUNDQ1ZBw8eTG2YGBKZ9bvf/a71xz/+0bIsy7rvvvus\nvr6+FKeZ3/lktSzLevrpp61vfvObc75P0+2YZFlnzpmOxyTLOnNWy0rsMWlR7Kjnu7rZ+Pi4SkpK\ntHTpUuXm5qqyslKHDh0662NGR0dVVVUlSaqpqdHg4GCK05xdInP6fD5deeWVkqSTJ08qLy8vxWnm\nl8isk5OT8vl82rVrV+qDxJDInH/961/10UcfafPmzXrppZei38emSGTWK6+8Up9++qksy1IkEjHu\n2gvnk1WSSkpK9JOf/GTO35VuxyTpzDnT8ZgknTlroo9Ji6Kow+GwCgoKorezs7N14sSJ6H1OpzN6\nn8PhUDgcPutjLMuSzWaLzg2FQilKEVsic1588cWS/v/g3tXVpc2bN6cmRJwSlXVmZka7d+/Wzp07\n5XA4UhcgTol8TY8dO6bCwkI999xzuuSSS/TMM8+kLkgcEpn1sssu0yOPPKKbb75ZExMTWrt2beqC\nxOF8skpSbW3taW860u2YJJ05Zzoek6TTs548eTLhx6RFUdTzXd3sy/dFIhE5nc6zPiYrK2vO3MLC\nwhQkiE8ic0rSb37zG7W2turpp59WUVFRilLEJ1FZx8bGdPToUT344IO677779O677+qRRx5JXZAY\nEvmaLlu2TDfc8P+fSHbDDTcYd938RGZ95JFH9Pzzz+u3v/2t6urqjPswn/PJejbpdkyaT7odk85k\ndHQ04cekRVHU813d7PLLL9fRo0f16aefamZmRq+99prKy8vP+pjVq1dreHhYkjQwMKA1a9akOM3Z\nJTLnr371K3V1dcnv9+srX/lK6sPEkKisZWVlevnll+X3++Xz+XTFFVdo9+7dC5LpTBL5mlZWVqq/\nv1+SdOjQIV1xxRUpTjO/RGZdunRpdHdz8cUX67PPPktxmvmdT9azSbdj0tmk4zHpTJJxTFoUFzw5\n09XN3nrrLX3++efauHGjDhw4oCeeeEKWZemWW27Rpk2bznpFtCNHjqilpUXHjx9XaWmpHn74YWVn\nZy90REmJy3nZZZdp3bp1uuSSS6Lvzr/2ta/p3nvvXeCE/5bI13TWe++9p/vuu++038hcSInMeezY\nMe3Zs0dffPGFCgoK1N7erqVLly50xKhEZn3ttdf0wx/+UHa7XTk5OXrooYe0YsWKhY4YdT5ZZ335\n+zTdjkmz/jPnyZMn0/KYNOtsx55EHZMWRVEDAJCpFsWpbwAAMhVFDQCAwShqAAAMRlEDAGAwihoA\nAINR1AAAGIyiBgDAYBQ1AAAG+z8swB6SPIOlMQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1117e4ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normalize_hillshade = normalize(train_data[['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']], axis=0)\n",
    "plt.hist(normalize_hillshade);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fe_train_data['Hillshade_9am'] = normalize_hillshade[:, 0]\n",
    "fe_train_data['Hillshade_Noon'] = normalize_hillshade[:, 1]\n",
    "fe_train_data['Hillshade_3pm'] = normalize_hillshade[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# baseline model\n",
    "# Check to see if any improvement relative to original baseline accuracy shown below (Baseline model score, mean=0.7762, stdDev=0.0412)\n",
    "\n",
    "X_train_mod = train_mod.iloc[:,:-1].values\n",
    "y_train_mod = train_mod.iloc[:,-1:].values.ravel()\n",
    "\n",
    "# Fit the baseline model with the cross validates params on the original feature set\n",
    "\n",
    "baseline_model = RandomForestClassifier(n_estimators=50,max_depth=76)\n",
    "baseline_model.fit(X_train_mod,y_train_mod)\n",
    "\n",
    "scores = cross_val_score(baseline_model, X_train_mod, y_train_mod, cv=10)\n",
    "\n",
    "print(\"Baseline model score after inserting new feature ('Hydrology_Distance_Is_Negative'), mean : {:7.4f}, stdDev : {:7.4f}\".format(np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Scaling\n",
    "\n",
    "To ensure that all numerical values are seen as \"equally weighted\" by the algorithm, we scale all of the features with 0 as the mean and 1 as standard deviation. We scale the test dataset using the training dataset parameters to ensure the numerical values are seen as \"equally weighted.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(train_data)\n",
    "std_train_data = sc.transform(train_data)\n",
    "std_test_data = sc.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "Based on our intuition of the use case, the problem that we are trying to solve is a multi-class classification problem. We come to this conclusion because we are trying to fit 54 features (of cartographic information) into 7 classes (of forest cover types). For this reason, we will look into multi-class classification methods to see which model performs the best classification of the problem at hand. \n",
    "\n",
    "The multi-class classification methods that we will compare are:\n",
    "\n",
    "1. Logistic Regression (LR)\n",
    "2. Naive Bayes (NB)\n",
    "3. K-Nearest Neighbors (KNN)\n",
    "4. Support Vector Machine (SVM)\n",
    "5. Decision Tree (DT)\n",
    "6. Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem with train/test split\n",
    "* split the dataset into two pieces so that the model can be trained and tested on different data\n",
    "* problem: it provides a high variance estimate since changing which observations happen to be in the testing set can significantly change testing accuracy\n",
    "* testing accuracy can change a lot depending on which observation happen to be in the testing set\n",
    "\n",
    "Cross-validation: create multiple train/test split, calculate the testing accuracy for each, and average the results together \n",
    "\n",
    "define the parameters that will be searched using K-fold cross-validation\n",
    "\n",
    "Reducing computational expense using RandomizedSearchCV\n",
    "\n",
    "Searching many different parameters at once may be computationally infeasible\n",
    "* For example\n",
    "* Searching 10 parameters (each range of 1000)\n",
    "* Require 10,000 trials of CV\n",
    "* 100,000 model fits with 10-fold CV\n",
    "* 100,000 predictions with 10-fold CV\n",
    "\n",
    "RandomizedSearchCV searches a subset of the parameters, and you control the computational \"budget\"\n",
    "\n",
    "You can decide how long you want it to run for depending on the computational time we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The total space of parameters 1 is smaller than n_iter=10. For exhaustive searches, use GridSearchCV.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-66a30bd352c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mrscv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mrscv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0moutput_rscv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrscv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# print out params for the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1188\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m                                           random_state=self.random_state)\n\u001b[0;32m-> 1190\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchedCalls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                 \u001b[0;31m# No more tasks available in the iterator: tell caller to stop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, iterator_slice)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         )(delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n\u001b[0m\u001b[1;32m    558\u001b[0m                                   \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m                                   \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m                     \u001b[0;34m\"The total space of parameters %d is smaller \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                     \u001b[0;34m\"than n_iter=%d. For exhaustive searches, use \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                     \"GridSearchCV.\" % (grid_size, self.n_iter))\n\u001b[0m\u001b[1;32m    243\u001b[0m             for i in sample_without_replacement(grid_size, self.n_iter,\n\u001b[1;32m    244\u001b[0m                                                 random_state=rnd):\n",
      "\u001b[0;31mValueError\u001b[0m: The total space of parameters 1 is smaller than n_iter=10. For exhaustive searches, use GridSearchCV."
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Randomized Search Cross Validation \n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# define variable to store output\n",
    "output_rscv = [None] * 6\n",
    "\n",
    "# 1. Logistic Regression\n",
    "'''\n",
    "lr = LogisticRegression(multi_class='multinomial', penalty='l2', max_iter=100, random_state=random_state)\n",
    "param_grid = dict(solver=['newton-cg', 'lbfgs', 'sag'], \n",
    "                  C=[0.001, 0.01, 0.1, 1, 10, 100, 1000])\n",
    "rscv = RandomizedSearchCV(lr, param_grid, cv=10, scoring='accuracy')\n",
    "rscv.fit(train_data, train_labels)                                                                          \n",
    "output_rscv[0] = rscv.best_score_\n",
    "# print out params for the best model\n",
    "print('LR best params: {}'.format(rscv.best_params_))\n",
    "'''\n",
    "\n",
    "# 2. Naive Bayes\n",
    "nb = GaussianNB()\n",
    "param_grid = {}\n",
    "rscv = RandomizedSearchCV(nb, param_grid, cv=10, scoring='accuracy')\n",
    "rscv.fit(train_data, train_labels)                                                                          \n",
    "output_rscv[1] = rscv.best_score_\n",
    "# print out params for the best model\n",
    "print('NB best params: {}'.format(rscv.best_params_))\n",
    "                                                                          \n",
    "# 3. K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = dict(n_neighbors=range(1, 30), \n",
    "                  weights=['uniform', 'distance'])\n",
    "rscv = RandomizedSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
    "rscv.fit(train_data, train_labels)                                                                          \n",
    "output_rscv[2] = rscv.best_score_\n",
    "# print out params for the best model\n",
    "print('KNN best params: {}'.format(rscv.best_params_))\n",
    "\n",
    "# 4. Support Vector Machine\n",
    "svm = SVM.SVC(random_state=random_state) \n",
    "param_grid = dict(C=[0.001, 0.01, 0.1, 1, 10], \n",
    "                  gamma=[0.001, 0.01, 0.1, 1])\n",
    "rscv = RandomizedSearchCV(svm, param_grid, cv=10, scoring='accuracy')\n",
    "rscv.fit(train_data, train_labels)                                                                          \n",
    "output_rscv[3] = rscv.best_score_\n",
    "# print out params for the best model\n",
    "print('SVM best params: {}'.format(rscv.best_params_))\n",
    "                                                                          \n",
    "# 5. Decision Trees\n",
    "dt = DecisionTreeClassifier(random_state=random_state)\n",
    "param_grid = dict(criterion=['gini', 'entropy'], \n",
    "                  bootstrap=[True, False],\n",
    "                  max_depth=[None, 2, 5, 10],\n",
    "                  min_samples_split=[2, 10, 20],\n",
    "                  min_samples_leaf=[1, 5, 10],\n",
    "                  max_leaf_nodes=[None, 5, 10, 20])\n",
    "rscv = RandomizedSearchCV(dt, param_grid, cv=10, scoring='accuracy')\n",
    "rscv.fit(train_data, train_labels)                                                                          \n",
    "output_rscv[4] = rscv.best_score_\n",
    "# print out params for the best model\n",
    "print('NB best params: {}'.format(rscv.best_params_))                                                  \n",
    "\n",
    "# 6. Neural Networks\n",
    "nn = MLPClassifier(random_state=random_state)\n",
    "param_grid = dict(learning_rate=stats.uniform(0.001, 0.05),\n",
    "                  hidden0__units=range(4, 12),\n",
    "                  hideen0__type=['Rectifier', 'Sigmoid', 'Tanh'])\n",
    "rscv = RandomizedSearchCV(nn, param_grid, cv=10, scoring='accuracy')\n",
    "rscv.fit(train_data, train_labels)                                                                          \n",
    "output_rscv[5] = rscv.best_score_\n",
    "# print out params for the best model\n",
    "print('NB best params: {}'.format(rscv.best_params_))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Randomized Search Cross Validation w/ F.E. data\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# define variable to store output\n",
    "output_rscv_fe = [None] * 6\n",
    "\n",
    "# 1. Logistic Regression\n",
    "lr = LogisticRegression(multi_class='multinomial')\n",
    "param_grid = {}\n",
    "rscv = RandomizedSearchCV(lr, param_grid, cv=10, scoring='accuracy')\n",
    "rscv.fit(fe_train_data, fe_train_labels)                                                                          \n",
    "output_rscv_fe[0] = rscv.best_score_\n",
    "# print out params for the best model\n",
    "print('LR best params: {}'.format(rscv.best_params_))\n",
    "\n",
    "# 2. Naive Bayes\n",
    "nb = GaussianNB()\n",
    "param_grid = {}\n",
    "rscv = RandomizedSearchCV(nb, param_grid, cv=10, scoring='accuracy')\n",
    "rscv.fit(fe_train_data, fe_train_labels)                                                                          \n",
    "output_rscv_fe[1] = rscv.best_score_\n",
    "# print out params for the best model\n",
    "print('NB best params: {}'.format(rscv.best_params_))\n",
    "                                                                          \n",
    "# 3. K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = {n_neighbors=k_range}\n",
    "rscv = RandomizedSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
    "rscv.fit(fe_train_data, fe_train_labels)                                                                          \n",
    "output_rscv_fe[2] = rscv.best_score_\n",
    "# print out params for the best model\n",
    "print('KNN best params: {}'.format(rscv.best_params_))\n",
    "\n",
    "# 4. Support Vector Machine\n",
    "svm = SVM.SVC() \n",
    "param_grid = {}\n",
    "rscv = RandomizedSearchCV(svm, param_grid, cv=10, scoring='accuracy')\n",
    "rscv.fit(fe_train_data, fe_train_labels)                                                                          \n",
    "output_rscv_fe[3] = rscv.best_score_\n",
    "# print out params for the best model\n",
    "print('SVM best params: {}'.format(rscv.best_params_))\n",
    "                                                                          \n",
    "# 5. Decision Trees\n",
    "dt = DecisionTreeClassifier()\n",
    "param_grid = {}\n",
    "rscv = RandomizedSearchCV(dt, param_grid, cv=10, scoring='accuracy')\n",
    "rscv.fit(fe_train_data, fe_train_labels)                                                                          \n",
    "output_rscv_fe[4] = rscv.best_score_\n",
    "# print out params for the best model\n",
    "print('NB best params: {}'.format(rscv.best_params_))                                                  \n",
    "\n",
    "# 6. Neural Networks\n",
    "#mlp = MLPClassifier()\n",
    "#mlp.fit(fe_train_data, fe_train_labels)                                                    \n",
    "#output_cv_fe[5] = cross_val_score(mlp, fe_train_data, fe_train_labels, cv=10, scoring='accuracy').mean()\n",
    "output_rscv_fe[5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Grid Search Cross Validation w/ F.E. data\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# define variable to store output\n",
    "output_gscv_fe = [None] * 6\n",
    "\n",
    "# 1. Logistic Regression\n",
    "lr = LogisticRegression(multi_class='multinomial')\n",
    "param_grid = {}\n",
    "gscv = GridSearchCV(lr, param_grid, cv=10, scoring='accuracy')\n",
    "gscv.fit(fe_train_data, fe_train_labels)                                                                          \n",
    "output_gscv_fe[0] = gscv.best_score_\n",
    "# print out params for the best model\n",
    "print('LR best params: {}'.format(gscv.best_params_))\n",
    "\n",
    "# 2. Naive Bayes\n",
    "nb = GaussianNB()\n",
    "param_grid = {}\n",
    "gscv = GridSearchCV(nb, param_grid, cv=10, scoring='accuracy')\n",
    "gscv.fit(fe_train_data, fe_train_labels)                                                                          \n",
    "output_gscv_fe[1] = gscv.best_score_\n",
    "# print out params for the best model\n",
    "print('NB best params: {}'.format(gscv.best_params_))\n",
    "                                                                          \n",
    "# 3. K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = {n_neighbors=k_range}\n",
    "gscv = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
    "gscv.fit(fe_train_data, fe_train_labels)                                                                          \n",
    "output_gscv_fe[2] = gscv.best_score_\n",
    "# print out params for the best model\n",
    "print('KNN best params: {}'.format(gscv.best_params_))\n",
    "\n",
    "# 4. Support Vector Machine\n",
    "svm = SVM.SVC() \n",
    "param_grid = {}\n",
    "gscv = GridSearchCV(svm, param_grid, cv=10, scoring='accuracy')\n",
    "gscv.fit(fe_train_data, fe_train_labels)                                                                          \n",
    "output_gscv_fe[3] = gscv.best_score_\n",
    "# print out params for the best model\n",
    "print('SVM best params: {}'.format(gscv.best_params_))\n",
    "                                                                          \n",
    "# 5. Decision Trees\n",
    "dt = DecisionTreeClassifier()\n",
    "param_grid = {}\n",
    "gscv = GridSearchCV(dt, param_grid, cv=10, scoring='accuracy')\n",
    "gscv.fit(fe_train_data, fe_train_labels)                                                                          \n",
    "output_gscv_fe[4] = gscv.best_score_\n",
    "# print out params for the best model\n",
    "print('NB best params: {}'.format(gscv.best_params_))                                                  \n",
    "\n",
    "# 6. Neural Networks\n",
    "#mlp = MLPClassifier()\n",
    "#mlp.fit(fe_train_data, fe_train_labels)                                                    \n",
    "#output_cv_fe[5] = cross_val_score(mlp, fe_train_data, fe_train_labels, cv=10, scoring='accuracy').mean()\n",
    "output_gscv_fe[5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(train_data)\n",
    "std_s_fe_train_data = sc.transform(s_fe_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_regions(X,y,classifier,test_idx=None,resolution=0.02):\n",
    "    \n",
    "    # Initialise the marker types and colors\n",
    "    markers = ('s','x','o','^','v')\n",
    "    colors = ('red','blue','lightgreen','gray','cyan')\n",
    "    color_Map = ListedColormap(colors[:len(np.unique(y))]) #we take the color mapping correspoding to the \n",
    "                                                            #amount of classes in the target data\n",
    "    \n",
    "    # Parameters for the graph and decision surface\n",
    "    x1_min = X[:,0].min() - 1\n",
    "    x1_max = X[:,0].max() + 1\n",
    "    x2_min = X[:,1].min() - 1\n",
    "    x2_max = X[:,1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min,x1_max,resolution),\n",
    "                           np.arange(x2_min,x2_max,resolution))\n",
    "    \n",
    "    Z = classifier.predict(np.array([xx1.ravel(),xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    \n",
    "    plt.contour(xx1,xx2,Z,alpha=0.4,cmap = color_Map)\n",
    "    plt.xlim(xx1.min(),xx1.max())\n",
    "    plt.ylim(xx2.min(),xx2.max())\n",
    "    \n",
    "    # Plot samples\n",
    "    X_test, Y_test = X[test_idx,:], y[test_idx]\n",
    "    \n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x = X[y == cl, 0], y = X[y == cl, 1],\n",
    "                    alpha = 0.8, c = color_Map(idx),\n",
    "                    marker = markers[idx], label = cl\n",
    "                   )\n",
    "\n",
    "\n",
    "x = np.vstack((s_fe_train_data, s_fe_dev_data))\n",
    "y = np.hstack((s_fe_train_labels, s_fe_dev_labels))\n",
    "plot_decision_regions(X=x, y=y, classifier=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages of cross-validation:\n",
    "* More accurate estimate of out-of-sample accuracy\n",
    "* More \"efficient\" use of data (every observation is used for both training and testing\n",
    "\n",
    "Advantages of train/t/est split:\n",
    "* Runs K times faster than K-fold cross-validation\n",
    "* Simpler to examine the detailed results of the testing process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model-results'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('goal better than {}'.format(1/7))\n",
    "pd.DataFrame({'Randomized Search CV': output_rscv, 'Randomized Search CV + FE': output_rscv_fe}, \n",
    "             columns=['Randomized Search CV', 'Randomized Search CV'],\n",
    "             index=['Logistic Regression', 'Naive Bayes', 'KNN', 'SVM', 'Decision Trees', 'Neural Networks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ensemble-models'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ensemble-results'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goal better than 0.14285714285714285\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base Case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.692130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.595238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.798942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.149802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Trees</th>\n",
       "      <td>0.785384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Networks</th>\n",
       "      <td>0.538690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Base Case\n",
       "Logistic Regression   0.692130\n",
       "Naive Bayes           0.595238\n",
       "KNN                   0.798942\n",
       "SVM                   0.149802\n",
       "Decision Trees        0.785384\n",
       "Neural Networks       0.538690"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('goal better than {}'.format(1/7))\n",
    "pd.DataFrame({'Base Case': output_bc}, \n",
    "             columns=['Base Case'],\n",
    "             index=['Logistic Regression', 'Naive Bayes', 'KNN', 'SVM', 'Decision Trees', 'Neural Networks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ensemble-models'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='stack-results'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goal better than 0.14285714285714285\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base Case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.692130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.595238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.798942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.149802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Trees</th>\n",
       "      <td>0.785384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Networks</th>\n",
       "      <td>0.538690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Base Case\n",
       "Logistic Regression   0.692130\n",
       "Naive Bayes           0.595238\n",
       "KNN                   0.798942\n",
       "SVM                   0.149802\n",
       "Decision Trees        0.785384\n",
       "Neural Networks       0.538690"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('goal better than {}'.format(1/7))\n",
    "pd.DataFrame({'Base Case': output_bc}, \n",
    "             columns=['Base Case'],\n",
    "             index=['Logistic Regression', 'Naive Bayes', 'KNN', 'SVM', 'Decision Trees', 'Neural Networks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusion'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='references'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. Bache, K. & Lichman, M. (2013). UCI Machine Learning Repository. Irvine, CA: University of California, School of Information and Computer Science\n",
    "2. Colorado's Major Tree Species. Colorado State Forest Service, csfs.colostate.edu/colorado-trees/colorados-major-tree-species/#1466527937174-cd5c5e60-5efc.\n",
    "3. Slope, Aspect, and Hillshade. GEOG 571: Intelligence Analysis, Cultural Geography, and Homeland Security, www.e-education.psu.edu/geog480/node/490.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='appendix'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='appendix-cv'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix: Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default params for base case:\n",
    "\n",
    "```\n",
    "1. LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
    "          n_jobs=1, penalty='l2', random_state=7, solver='newton-cg',\n",
    "          tol=0.0001, verbose=0, warm_start=False)\n",
    "2. GaussianNB(priors=None)\n",
    "3. KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "           weights='uniform')\n",
    "4. SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "       decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
    "       max_iter=-1, probability=False, random_state=7, shrinking=True,\n",
    "       tol=0.001, verbose=False)\n",
    "5. DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=7, splitter='best')\n",
    "6. MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
    "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=7,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=False, warm_start=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Train/Test Split\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# define variable to store output\n",
    "output_tts = [None] * 6\n",
    "\n",
    "# subset train data into dev data\n",
    "# train_data -> 80% s_train_data, 20% s_dev_data\n",
    "s_train_data, s_dev_data, s_train_labels, s_dev_labels = train_test_split(train_data, train_labels, stratify=train_labels, test_size=0.2, random_state=random_state)\n",
    "                                                                          \n",
    "# 1. Logistic Regression\n",
    "lr = LogisticRegression(multi_class='multinomial', penalty='l2', solver='newton-cg', random_state=random_state)\n",
    "lr.fit(s_train_data, s_train_labels)\n",
    "pred_dev_labels = lr.predict(s_dev_data)\n",
    "output_tts[0] = accuracy_score(s_dev_labels, pred_dev_labels)\n",
    "\n",
    "# 2. Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(s_train_data, s_train_labels)\n",
    "pred_dev_labels = nb.predict(s_dev_data)\n",
    "output_tts[1] = accuracy_score(s_dev_labels, pred_dev_labels)\n",
    "                                                                          \n",
    "# 3. K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(s_train_data, s_train_labels)                                                                          \n",
    "pred_dev_labels = knn.predict(s_dev_data)\n",
    "output_tts[2] = accuracy_score(s_dev_labels, pred_dev_labels)\n",
    "                                                                          \n",
    "# 4. Support Vector Machine\n",
    "svm = SVM.SVC(random_state=random_state) \n",
    "svm.fit(s_train_data, s_train_labels)                                                    \n",
    "pred_dev_labels = svm.predict(s_dev_data)\n",
    "output_tts[3] = accuracy_score(s_dev_labels, pred_dev_labels)\n",
    "                                                                          \n",
    "# 5. Decision Trees\n",
    "dt = DecisionTreeClassifier(random_state=random_state)\n",
    "dt.fit(s_train_data, s_train_labels)                                                    \n",
    "pred_dev_labels = dt.predict(s_dev_data)\n",
    "output_tts[4] = accuracy_score(s_dev_labels, pred_dev_labels)                                                                      \n",
    "\n",
    "# 6. Neural Networks\n",
    "mlp = MLPClassifier(random_state=random_state)\n",
    "mlp.fit(s_train_data, s_train_labels)                                                    \n",
    "pred_dev_labels = mlp.predict(s_dev_data)\n",
    "output_tts[5] = accuracy_score(s_dev_labels, pred_dev_labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Train/Test Split w/ F.E. data\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# define variable to store output\n",
    "output_tts_fe = [None] * 6\n",
    "\n",
    "# subset feature engineering's train data into dev data\n",
    "# fe_train_data -> 80% s_fe_train_data, 20% s_fe_dev_data\n",
    "s_fe_train_data, s_fe_dev_data, s_fe_train_labels, s_fe_dev_labels = train_test_split(fe_train_data, fe_train_labels, stratify=fe_train_labels, test_size=0.2, random_state=random_state)\n",
    "                                                                          \n",
    "# 1. Logistic Regression\n",
    "lr = LogisticRegression(multi_class='multinomial', penalty='l2', solver='newton-cg', random_state=random_state)\n",
    "lr.fit(s_fe_train_data, s_fe_train_labels)\n",
    "pred_dev_labels = lr.predict(s_fe_dev_data)\n",
    "output_tts_fe[0] = accuracy_score(s_fe_dev_labels, pred_dev_labels)\n",
    "\n",
    "# 2. Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(s_fe_train_data, s_fe_train_labels)\n",
    "pred_dev_labels = nb.predict(s_fe_dev_data)\n",
    "output_tts_fe[1] = accuracy_score(s_fe_dev_labels, pred_dev_labels)\n",
    "                                                                          \n",
    "# 3. K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(s_fe_train_data, s_fe_train_labels)                                                                          \n",
    "pred_dev_labels = knn.predict(s_fe_dev_data)\n",
    "output_tts_fe[2] = accuracy_score(s_fe_dev_labels, pred_dev_labels)\n",
    "                                                                          \n",
    "# 4. Support Vector Machine\n",
    "svm = SVM.SVC() \n",
    "svm.fit(s_fe_train_data, s_fe_train_labels)                                                    \n",
    "pred_dev_labels = svm.predict(s_fe_dev_data)\n",
    "output_tts_fe[3] = accuracy_score(s_fe_dev_labels, pred_dev_labels)\n",
    "                                                                          \n",
    "# 5. Decision Trees\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(s_fe_train_data, s_fe_train_labels)                                                    \n",
    "pred_dev_labels = dt.predict(s_fe_dev_data)\n",
    "output_tts_fe[4] = accuracy_score(s_fe_dev_labels, pred_dev_labels)                                                                      \n",
    "\n",
    "# 6. Neural Networks\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(s_fe_train_data, s_fe_train_labels)                                                    \n",
    "pred_dev_labels = mlp.predict(s_fe_dev_data)\n",
    "output_tts_fe[5] = accuracy_score(s_fe_dev_labels, pred_dev_labels)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Cross Validation w/ F.E. data\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# define variable to store output\n",
    "output_cv = [None] * 6\n",
    "                                                      \n",
    "# 1. Logistic Regression\n",
    "lr = LogisticRegression(multi_class='multinomial', penalty='l2', solver='newton-cg', random_state=random_state)\n",
    "lr.fit(train_data, train_labels)\n",
    "output_cv[0] = cross_val_score(lr, train_data, train_labels, cv=10, scoring='accuracy').mean()\n",
    "\n",
    "# 2. Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(train_data, train_labels)\n",
    "output_cv[1] = cross_val_score(nb, train_data, train_labels, cv=10, scoring='accuracy').mean()\n",
    "                                                                          \n",
    "# 3. K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(train_data, train_labels)                                                                          \n",
    "output_cv[2] = cross_val_score(knn, train_data, train_labels, cv=10, scoring='accuracy').mean()\n",
    "                                                                          \n",
    "# 4. Support Vector Machine\n",
    "svm = SVM.SVC() \n",
    "svm.fit(train_data, train_labels)                                                    \n",
    "output_cv[3] = cross_val_score(svm, train_data, train_labels, cv=10, scoring='accuracy').mean()\n",
    "                                                                          \n",
    "# 5. Decision Trees\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(train_data, train_labels)                                                    \n",
    "output_cv[4] = cross_val_score(dt, train_data, train_labels, cv=10, scoring='accuracy').mean()                                                      \n",
    "\n",
    "# 6. Neural Networks\n",
    "#mlp = MLPClassifier()\n",
    "#mlp.fit(train_data, train_labels)                                                    \n",
    "#output_cv[5] = cross_val_score(mlp, train_data, train_labels, cv=10, scoring='accuracy').mean()\n",
    "output_cv[5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/tiffapedia/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Cross Validation w/ F.E. data\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# define variable to store output\n",
    "output_cv_fe = [None] * 6\n",
    "\n",
    "# 1. Logistic Regression\n",
    "lr = LogisticRegression(multi_class='multinomial', penalty='l2', solver='newton-cg', random_state=random_state)\n",
    "lr.fit(fe_train_data, fe_train_labels)\n",
    "output_cv_fe[0] = cross_val_score(lr, fe_train_data, fe_train_labels, cv=10, scoring='accuracy').mean()\n",
    "\n",
    "# 2. Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(fe_train_data, fe_train_labels)\n",
    "output_cv_fe[1] = cross_val_score(nb, fe_train_data, fe_train_labels, cv=10, scoring='accuracy').mean()\n",
    "                                                                          \n",
    "# 3. K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(fe_train_data, fe_train_labels)                                                                          \n",
    "output_cv_fe[2] = cross_val_score(knn, fe_train_data, fe_train_labels, cv=10, scoring='accuracy').mean()\n",
    "                                                                          \n",
    "# 4. Support Vector Machine\n",
    "svm = SVM.SVC() \n",
    "svm.fit(fe_train_data, fe_train_labels)                                                    \n",
    "output_cv_fe[3] = cross_val_score(svm, fe_train_data, fe_train_labels, cv=10, scoring='accuracy').mean()\n",
    "                                                                          \n",
    "# 5. Decision Trees\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(fe_train_data, fe_train_labels)                                                    \n",
    "output_cv_fe[4] = cross_val_score(dt, fe_train_data, fe_train_labels, cv=10, scoring='accuracy').mean()                                                      \n",
    "\n",
    "# 6. Neural Networks\n",
    "#mlp = MLPClassifier()\n",
    "#mlp.fit(fe_train_data, fe_train_labels)                                                    \n",
    "#output_cv_fe[5] = cross_val_score(mlp, fe_train_data, fe_train_labels, cv=10, scoring='accuracy').mean()\n",
    "output_cv_fe[5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goal better than 0.14285714285714285\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train/Test Split</th>\n",
       "      <th>Train/Test Split + FE</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th>Cross Validation + FE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.692130</td>\n",
       "      <td>0.663029</td>\n",
       "      <td>0.655622</td>\n",
       "      <td>0.626058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.578042</td>\n",
       "      <td>0.569114</td>\n",
       "      <td>0.561111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.798942</td>\n",
       "      <td>0.796627</td>\n",
       "      <td>0.685979</td>\n",
       "      <td>0.681283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.149802</td>\n",
       "      <td>0.153770</td>\n",
       "      <td>0.146098</td>\n",
       "      <td>0.147288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Trees</th>\n",
       "      <td>0.774802</td>\n",
       "      <td>0.784722</td>\n",
       "      <td>0.712698</td>\n",
       "      <td>0.713228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Networks</th>\n",
       "      <td>0.568122</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Train/Test Split  Train/Test Split + FE  \\\n",
       "Logistic Regression          0.692130               0.663029   \n",
       "Naive Bayes                  0.595238               0.578042   \n",
       "KNN                          0.798942               0.796627   \n",
       "SVM                          0.149802               0.153770   \n",
       "Decision Trees               0.774802               0.784722   \n",
       "Neural Networks              0.568122               0.446429   \n",
       "\n",
       "                     Cross Validation  Cross Validation + FE  \n",
       "Logistic Regression          0.655622               0.626058  \n",
       "Naive Bayes                  0.569114               0.561111  \n",
       "KNN                          0.685979               0.681283  \n",
       "SVM                          0.146098               0.147288  \n",
       "Decision Trees               0.712698               0.713228  \n",
       "Neural Networks              0.000000               0.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('goal better than {}'.format(np.round(1/7, 4))\n",
    "pd.DataFrame({'Train/Test Split': output_tts, 'Train/Test Split + FE': output_tts_fe,\n",
    "              'Cross Validation': output_cv, 'Cross Validation + FE': output_cv_fe}, \n",
    "             columns=['Train/Test Split', 'Train/Test Split + FE',\n",
    "                      'Cross Validation', 'Cross Validation + FE'],\n",
    "             index=['Logistic Regression', 'Naive Bayes', 'KNN', 'SVM', 'Decision Trees', 'Neural Networks'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
